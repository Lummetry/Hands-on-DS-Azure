{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport utils\nutils.set_pretty_prints()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/matplotlib/font_manager.py:229: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch as th\nth.__version__",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "'1.3.1'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from torchvision.datasets import MNIST",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist_data_train = MNIST('./datasets', download=True, train=True)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\r0it [00:00, ?it/s]",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "9920512it [00:06, 1603487.95it/s]                             \n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "  0%|          | 0/28881 [00:00<?, ?it/s]",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "32768it [00:00, 131431.61it/s]           \n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "  0%|          | 0/1648877 [00:00<?, ?it/s]",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "1654784it [00:01, 1389613.09it/s]                             \n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "8192it [00:00, 69628.12it/s]",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\nExtracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Processing...\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "type(mnist_data_train)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "torchvision.datasets.mnist.MNIST"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(mnist_data_train)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "60000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist_data_train[0]",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "(<PIL.Image.Image image mode=L size=28x28 at 0x7FCB6A181DA0>, 5)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist_data_train[0][0]",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": "<PIL.Image.Image image mode=L size=28x28 at 0x7FCB6A181D68>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist_test_data = MNIST('./datasets', train=False, transform=lambda x: (np.array(x)/255.).astype('float32'))",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(mnist_test_data)",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "10000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist_test_data[100][0]",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.5 , 0.87, 0.2 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.25, 0.9 , 0.86, 0.41, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05,\n        0.92, 0.55, 0.02, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.46,\n        0.89, 0.1 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.93,\n        0.52, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.95,\n        0.36, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.95,\n        0.08, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.74, 0.93,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.82, 0.66,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.59, 0.59, 0.53, 0.29,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 1.  , 0.35,\n        0.  , 0.  , 0.  , 0.  , 0.02, 0.56, 1.  , 0.88, 0.83, 0.71, 0.95,\n        0.27, 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 1.  , 0.27,\n        0.  , 0.  , 0.  , 0.01, 0.63, 1.  , 0.41, 0.03, 0.  , 0.  , 0.31,\n        0.87, 0.06, 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 1.  , 0.06,\n        0.  , 0.  , 0.  , 0.59, 0.91, 0.27, 0.  , 0.  , 0.  , 0.  , 0.04,\n        0.91, 0.1 , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 1.  , 0.06,\n        0.  , 0.  , 0.09, 0.89, 0.26, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.77, 0.34, 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 1.  , 0.17,\n        0.  , 0.  , 0.45, 0.98, 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.77, 0.39, 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.9 , 0.58,\n        0.  , 0.  , 0.24, 1.  , 0.27, 0.  , 0.  , 0.  , 0.  , 0.  , 0.02,\n        0.82, 0.33, 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.8 , 0.91,\n        0.02, 0.  , 0.16, 0.99, 0.29, 0.  , 0.  , 0.  , 0.  , 0.  , 0.45,\n        0.91, 0.07, 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.99,\n        0.58, 0.  , 0.  , 0.6 , 0.9 , 0.52, 0.48, 0.48, 0.25, 0.36, 0.97,\n        0.25, 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.66,\n        0.98, 0.54, 0.09, 0.03, 0.31, 0.39, 0.4 , 0.42, 0.57, 0.75, 0.2 ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02,\n        0.55, 0.98, 0.88, 0.56, 0.45, 0.45, 0.76, 1.  , 0.73, 0.19, 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.22, 0.55, 0.8 , 0.96, 0.71, 0.51, 0.26, 0.01, 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]], dtype=float32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist_test_data[100][1]",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "6"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th.cuda.is_available()",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "False"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dev = th.device('cuda' if th.cuda.is_available() else 'cpu')",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_x_train = th.tensor([(np.array(x[0])/255).astype('float32') for x in mnist_data_train])\nth_y_train = th.tensor([x[1] for x in mnist_data_train])",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_x_train = th_x_train.to(dev)\nth_y_train = th_y_train.to(dev)",
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_x_test = th.tensor([x[0] for x in mnist_test_data])",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "np_y_test = np.array([x[1] for x in mnist_test_data])",
      "execution_count": 87,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_x_test.shape",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "torch.Size([10000, 28, 28])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_x_train.shape",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "torch.Size([60000, 28, 28])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# tf uses BHWC\n# th uses BCHW\nth_x_train = th_x_train.unsqueeze(1)\nth_x_train.shape",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "torch.Size([60000, 1, 28, 28])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_x_test = th_x_test.unsqueeze(1)\nth_x_test.shape",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "torch.Size([10000, 1, 28, 28])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "batch_size = 128",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_dataloader = th.utils.data.DataLoader(\n    dataset=th.utils.data.TensorDataset(th_x_train, th_y_train),\n    batch_size = batch_size,\n    shuffle=True,\n)",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for i, batch in enumerate(th_dataloader):\n    th_x_batch, th_y_batch = batch\n    break\n\nth_x_batch.shape",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "torch.Size([128, 1, 28, 28])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_y_batch.shape",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "torch.Size([128])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "th_x_batch[0,0]",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1020,\n         0.6000, 0.9961, 1.0000, 0.4157, 0.2196, 0.2196, 0.1294, 0.0863, 0.0980,\n         0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4863,\n         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9216, 0.8902, 0.8980,\n         0.8784, 0.8235, 0.8196, 0.5608, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.8941,\n         0.9922, 0.9647, 0.7373, 0.7373, 0.7373, 0.5059, 0.7686, 0.8353, 0.7373,\n         0.8078, 0.7922, 0.9922, 0.9922, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4118, 0.9961,\n         0.9922, 0.9333, 0.1294, 0.0000, 0.0000, 0.0000, 0.0588, 0.0510, 0.0000,\n         0.0392, 0.1451, 0.9922, 0.9961, 0.8078, 0.0196, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.9922,\n         0.9922, 0.7961, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.4941, 0.9922, 0.9961, 0.8902, 0.0275, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.6863, 0.9922,\n         0.9922, 0.2863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.1882, 0.7490, 0.9922, 0.9765, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9922, 0.9922,\n         0.8941, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0235,\n         0.7765, 0.9961, 0.8902, 0.5686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.9922, 0.9490,\n         0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431,\n         0.9922, 0.9412, 0.3098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.8980, 0.4235,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.9569,\n         0.9922, 0.8980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0118, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.4039, 0.5843, 0.6627, 0.8235, 0.9882, 0.9922,\n         0.9922, 0.8196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0078, 0.3765, 0.6941, 0.9843, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n         0.8745, 0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.5373, 0.9922, 0.8235, 0.5412, 0.5137, 0.9922, 0.9922, 0.9961, 0.9569,\n         0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.1059, 0.4627, 0.0431, 0.0000, 0.0235, 0.9804, 0.9922, 0.9922, 0.4314,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.4824, 0.9922, 0.9922, 0.7294, 0.0510,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.7647, 0.9922, 0.9765, 0.0431, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.3922, 0.9255, 0.9922, 0.6980, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0471, 0.9176, 0.9961, 0.9176, 0.1490, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.4745, 0.9922, 0.9961, 0.9922, 0.1922, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.7255, 0.9922, 0.9961, 0.8824, 0.0863, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.5686, 0.9922, 0.8471, 0.1765, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n         0.0000]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class GlobalMaxPooling2D(th.nn.Module):\n    def forward(self, th_x):\n        pool_window = th_x.shape[2], th_x.shape[3]\n        th_pooled = th.nn.functional.max_pool2d(th_x, kernel_size=pool_window)\n        # B, C, 1, 1\n        th_squeezed = th.squeeze(th_pooled)\n        return th_squeezed\n    \nclass Flatten(th.nn.Module):\n    def forward(self, th_x):\n        return th.flatten(th_x, start_dim=1)\n\nclass MNISTClassifier(th.nn.Module):\n    def __init__(self, input_shape=(1, 28, 28), filters=[32, 64], kernels=[5,3], strides=[2,1], dropout=0.5, activation=th.nn.ReLU, gmp=True):\n        super().__init__()\n        self.layers = th.nn.ModuleList()\n        in_channels = input_shape[0]\n        in_h = input_shape[1]\n        for i, flt in enumerate(filters):\n            kern = kernels[i]\n            stride = strides[i]\n            cnv_layer = th.nn.Conv2d(in_channels, flt, kernel_size=kern, stride=stride)\n            self.layers.append(cnv_layer)\n            in_channels = flt\n            self.layers.append(activation())\n            self.layers.append(th.nn.Dropout(dropout))\n            out_h = int((in_h - kern) / stride + 1)\n            in_h = out_h\n            print(\"Layer {}: out volume is {}\".format(i + 1, (flt, out_h, out_h)))\n        if gmp:\n            self.flat_layer = GlobalMaxPooling2D()\n            self.out_layer = th.nn.Linear(filters[-1], 10)\n        else:\n            self.flat_layer = Flatten()\n            self.out_layer = th.nn.Linear(out_h * out_h * filters[-1], 10)\n        return\n            \n        \n    def forward(self, th_x):\n        for layer in self.layers:\n            th_x = layer(th_x)\n        th_x = self.flat_layer(th_x)\n        th_x = self.out_layer(th_x)\n        return th_x\n        ",
      "execution_count": 64,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gmp = GlobalMaxPooling2D()",
      "execution_count": 65,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t1 = th.tensor(np.arange(24).reshape(2,3,2,2).astype('float32'))\nt1",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 66,
          "data": {
            "text/plain": "tensor([[[[ 0.,  1.],\n          [ 2.,  3.]],\n\n         [[ 4.,  5.],\n          [ 6.,  7.]],\n\n         [[ 8.,  9.],\n          [10., 11.]]],\n\n\n        [[[12., 13.],\n          [14., 15.]],\n\n         [[16., 17.],\n          [18., 19.]],\n\n         [[20., 21.],\n          [22., 23.]]]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t1.shape",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "torch.Size([2, 3, 2, 2])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gmp(t1)",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 68,
          "data": {
            "text/plain": "tensor([[ 3.,  7., 11.],\n        [15., 19., 23.]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "gmp(t1).shape",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 69,
          "data": {
            "text/plain": "torch.Size([2, 3])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th.flatten(t1, start_dim=1)",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n        [12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th.flatten(t1, start_dim=1).shape",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "torch.Size([2, 12])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = MNISTClassifier(filters=[16, 32, 64], kernels=[5, 5, 3], strides=[2,2,1], gmp=False).to(dev)",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Layer 1: out volume is (16, 12, 12)\nLayer 2: out volume is (32, 4, 4)\nLayer 3: out volume is (64, 2, 2)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 93,
          "data": {
            "text/plain": "MNISTClassifier(\n  (layers): ModuleList(\n    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 2))\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n    (4): ReLU()\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n    (7): ReLU()\n    (8): Dropout(p=0.5, inplace=False)\n  )\n  (flat_layer): Flatten()\n  (out_layer): Linear(in_features=256, out_features=10, bias=True)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "np_y_test.shape",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 94,
          "data": {
            "text/plain": "(10000,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "epochs = 10\ndef predict(model, th_x):\n    model.eval()\n    with th.no_grad():\n        th_yh = model(th_x)\n        np_yh = th_yh.cpu().numpy()\n    model.train()\n    return np_yh",
      "execution_count": 95,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "loss_fn = th.nn.CrossEntropyLoss()\nopt = th.optim.Adam(\n    params=model.parameters(),\n    lr=0.001,\n)\nnr_batches = th_x_train.shape[0] // batch_size\nfor epoch in range(1, epochs +1):\n    epoch_losses = []\n    for i, batch in enumerate(th_dataloader):\n        th_x_batch, th_y_batch = batch\n        th_yh = model(th_x_batch)\n        th_loss = loss_fn(input=th_yh, target=th_y_batch)\n        opt.zero_grad()\n        th_loss.backward()\n        opt.step()\n        epoch_losses.append(th_loss.detach().cpu().item())\n        if (i % 20) == 0:\n            print(\"\\rEpoch {} {:.1f}%, loss = {:.3f}\".format(epoch, i/nr_batches*100, np.mean(epoch_losses)), end='', flush=True)\n    np_y = predict(model, th_x_test)\n    np_preds = np_y.argmax(axis=1)\n    acc = (np_preds == np_y_test).sum() / np_y_test.shape[0]\n    print(\"\\rEpoch {} loss = {:.3f}. Test acc: {:.2f}\".format(epoch,  np.mean(epoch_losses), acc * 100))\n        \n        \n        ",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1 loss = 0.692. Test acc: 94.85\nEpoch 2 loss = 0.302. Test acc: 96.64\nEpoch 3 loss = 0.243. Test acc: 97.25\nEpoch 4 loss = 0.209. Test acc: 97.63\nEpoch 5 loss = 0.190. Test acc: 97.77\nEpoch 6 loss = 0.178. Test acc: 98.06\nEpoch 7 72.6%, loss = 0.167",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-d06dc2f9a60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mth_x_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth_y_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mth_yh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth_x_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mth_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mth_yh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mth_y_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-3e846de46ad7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, th_x)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mth_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mth_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mth_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_y_batch.shape",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 80,
          "data": {
            "text/plain": "torch.Size([128])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_y_batch",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 81,
          "data": {
            "text/plain": "tensor([6, 1, 0, 2, 0, 6, 9, 1, 3, 1, 8, 9, 3, 7, 4, 4, 6, 4, 3, 4, 7, 5, 0, 4,\n        0, 3, 3, 9, 4, 1, 3, 5, 3, 1, 0, 3, 9, 0, 7, 8, 8, 0, 0, 7, 2, 2, 0, 0,\n        9, 8, 8, 4, 2, 7, 6, 4, 7, 6, 5, 4, 4, 3, 8, 1, 0, 3, 5, 3, 3, 2, 8, 7,\n        5, 2, 3, 4, 7, 2, 7, 5, 4, 9, 2, 7, 9, 1, 3, 2, 3, 1, 2, 4, 2, 9, 8, 7,\n        8, 2, 0, 8, 6, 9, 8, 4, 2, 5, 8, 7, 6, 8, 7, 9, 7, 3, 5, 3, 6, 3, 1, 3,\n        6, 7, 9, 6, 6, 1, 3, 4])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_yh.shape",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 82,
          "data": {
            "text/plain": "torch.Size([128, 10])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th_yh[:10]",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 83,
          "data": {
            "text/plain": "tensor([[-0.0585, -0.0776, -0.0849, -0.1194, -0.0784, -0.1397,  0.0788,  0.0007,\n         -0.0019, -0.0116],\n        [-0.2173, -0.0008, -0.0965, -0.0705, -0.0226, -0.0871,  0.1068,  0.0442,\n          0.0141, -0.0362],\n        [-0.1127,  0.0579, -0.0075, -0.1578,  0.0351, -0.0378,  0.1197,  0.0020,\n          0.0859,  0.0515],\n        [-0.0501, -0.0377, -0.0439, -0.1291,  0.0311, -0.1141,  0.0307,  0.0009,\n          0.0478,  0.0139],\n        [-0.0842, -0.0735, -0.0645, -0.1466,  0.0540, -0.0811, -0.0077,  0.0766,\n          0.0062, -0.1257],\n        [-0.0791,  0.0244, -0.0250, -0.0552, -0.1483, -0.1737,  0.1183,  0.0969,\n          0.0667, -0.0797],\n        [-0.0288, -0.0864,  0.0107, -0.1790, -0.0737, -0.0451, -0.0009, -0.0105,\n         -0.0233,  0.0041],\n        [ 0.0306,  0.0526, -0.0656, -0.0387, -0.0117, -0.1367,  0.0675, -0.0209,\n          0.1009, -0.0019],\n        [-0.1094,  0.0195, -0.0487, -0.1390, -0.0464, -0.1406,  0.0937,  0.0649,\n          0.0520, -0.0706],\n        [-0.0206, -0.0163, -0.0953, -0.0083, -0.1652,  0.0327, -0.0008,  0.0185,\n          0.0324, -0.0402]], grad_fn=<SliceBackward>)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "th.nn.functional.softmax(th_yh[:10])",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  if __name__ == '__main__':\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 85,
          "data": {
            "text/plain": "tensor([[0.0989, 0.0970, 0.0963, 0.0930, 0.0969, 0.0912, 0.1134, 0.1049, 0.1046,\n         0.1036],\n        [0.0832, 0.1033, 0.0939, 0.0963, 0.1011, 0.0947, 0.1150, 0.1080, 0.1048,\n         0.0997],\n        [0.0887, 0.1052, 0.0986, 0.0848, 0.1029, 0.0956, 0.1119, 0.0995, 0.1082,\n         0.1046],\n        [0.0974, 0.0986, 0.0980, 0.0900, 0.1056, 0.0913, 0.1056, 0.1025, 0.1074,\n         0.1038],\n        [0.0959, 0.0969, 0.0978, 0.0901, 0.1101, 0.0962, 0.1035, 0.1126, 0.1050,\n         0.0920],\n        [0.0944, 0.1046, 0.0996, 0.0966, 0.0880, 0.0858, 0.1149, 0.1125, 0.1092,\n         0.0943],\n        [0.1013, 0.0956, 0.1054, 0.0872, 0.0969, 0.0997, 0.1042, 0.1032, 0.1019,\n         0.1047],\n        [0.1031, 0.1054, 0.0937, 0.0962, 0.0989, 0.0872, 0.1070, 0.0980, 0.1106,\n         0.0998],\n        [0.0923, 0.1050, 0.0981, 0.0896, 0.0983, 0.0895, 0.1131, 0.1099, 0.1085,\n         0.0959],\n        [0.1004, 0.1008, 0.0932, 0.1016, 0.0869, 0.1059, 0.1024, 0.1044, 0.1059,\n         0.0985]], grad_fn=<SoftmaxBackward>)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}